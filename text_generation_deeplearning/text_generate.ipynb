{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        x=f.read()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=read_file(\"moby_dick_four_chapters.txt\")\n",
    "#a=a.decode('utf-8') #to convert the file into string if it it is not one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Thasin Abedin\n",
      "[nltk_data]     Orvee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Thasin Abedin\n",
      "[nltk_data]     Orvee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "tokens= re.sub('[^a-zA-Z]', ' ', a)\n",
    "tokens = tokens.lower()\n",
    "tokens = tokens.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# organize into sequences of tokens of 25, leaving the 1st token of every precious token\n",
    "train_len = 25+1 # 25 training words , then one target word\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0]) #demo of taking 25 words removing the first word everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Keras Tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences=tokenizer.texts_to_sequences(text_sequences) #GIVES NUMERIC ID SEQUENCES OF THE TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 : call\n",
      "14 : me\n",
      "263 : ishmael\n",
      "51 : some\n",
      "261 : years\n",
      "411 : ago\n",
      "87 : never\n",
      "221 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "958 : precisely\n",
      "260 : having\n",
      "50 : little\n",
      "43 : or\n",
      "37 : no\n",
      "320 : money\n",
      "7 : in\n",
      "23 : my\n",
      "556 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "259 : particular\n",
      "6 : to\n",
      "2690 : interest\n",
      "14 : me\n",
      "25 : on\n"
     ]
    }
   ],
   "source": [
    "##TO SEE ID VALUES OF TOKENS USE TOKENIZER.INDEX_WORD\n",
    "#tokenizer.index_word\n",
    "#tokenizer.word_counts counts the no. of times one word showed up\n",
    "for i in sequences[0]:\n",
    "    print(f'{i} : {tokenizer.index_word[i]}') #NUMERIC ID VALUES FOR THE TOKENS WE HAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('call', 27),\n",
       "             ('me', 2471),\n",
       "             ('ishmael', 133),\n",
       "             ('some', 758),\n",
       "             ('years', 135),\n",
       "             ('ago', 84),\n",
       "             ('never', 449),\n",
       "             ('mind', 164),\n",
       "             ('how', 321),\n",
       "             ('long', 374),\n",
       "             ('precisely', 37),\n",
       "             ('having', 142),\n",
       "             ('little', 767),\n",
       "             ('or', 950),\n",
       "             ('no', 1029),\n",
       "             ('money', 120),\n",
       "             ('in', 5673),\n",
       "             ('my', 1812),\n",
       "             ('purse', 71),\n",
       "             ('and', 9646),\n",
       "             ('nothing', 281),\n",
       "             ('particular', 152),\n",
       "             ('to', 6497),\n",
       "             ('interest', 24),\n",
       "             ('on', 1716),\n",
       "             ('shore', 26),\n",
       "             ('i', 7332),\n",
       "             ('thought', 676),\n",
       "             ('would', 650),\n",
       "             ('sail', 104),\n",
       "             ('about', 1014),\n",
       "             ('a', 10403),\n",
       "             ('see', 442),\n",
       "             ('the', 15592),\n",
       "             ('watery', 26),\n",
       "             ('part', 234),\n",
       "             ('of', 8287),\n",
       "             ('world', 234),\n",
       "             ('it', 4420),\n",
       "             ('is', 1950),\n",
       "             ('way', 390),\n",
       "             ('have', 806),\n",
       "             ('driving', 26),\n",
       "             ('off', 416),\n",
       "             ('spleen', 26),\n",
       "             ('regulating', 26),\n",
       "             ('circulation', 26),\n",
       "             ('whenever', 130),\n",
       "             ('find', 78),\n",
       "             ('myself', 416),\n",
       "             ('growing', 26),\n",
       "             ('grim', 26),\n",
       "             ('mouth', 130),\n",
       "             ('damp', 78),\n",
       "             ('drizzly', 26),\n",
       "             ('november', 26),\n",
       "             ('soul', 78),\n",
       "             ('involuntarily', 52),\n",
       "             ('pausing', 52),\n",
       "             ('before', 364),\n",
       "             ('coffin', 130),\n",
       "             ('warehouses', 52),\n",
       "             ('bringing', 26),\n",
       "             ('up', 1237),\n",
       "             ('rear', 26),\n",
       "             ('every', 182),\n",
       "             ('funeral', 26),\n",
       "             ('meet', 26),\n",
       "             ('especially', 104),\n",
       "             ('hypos', 26),\n",
       "             ('get', 364),\n",
       "             ('such', 572),\n",
       "             ('an', 806),\n",
       "             ('upper', 26),\n",
       "             ('hand', 312),\n",
       "             ('that', 3770),\n",
       "             ('requires', 52),\n",
       "             ('strong', 78),\n",
       "             ('moral', 26),\n",
       "             ('principle', 26),\n",
       "             ('prevent', 26),\n",
       "             ('from', 1508),\n",
       "             ('deliberately', 26),\n",
       "             ('stepping', 26),\n",
       "             ('into', 988),\n",
       "             ('street', 104),\n",
       "             ('methodically', 26),\n",
       "             ('knocking', 26),\n",
       "             ('people', 52),\n",
       "             ('s', 1717),\n",
       "             ('hats', 26),\n",
       "             ('then', 832),\n",
       "             ('account', 78),\n",
       "             ('high', 130),\n",
       "             ('time', 520),\n",
       "             ('sea', 546),\n",
       "             ('as', 2366),\n",
       "             ('soon', 234),\n",
       "             ('can', 338),\n",
       "             ('this', 2184),\n",
       "             ('substitute', 26),\n",
       "             ('for', 1820),\n",
       "             ('pistol', 26),\n",
       "             ('ball', 26),\n",
       "             ('with', 2392),\n",
       "             ('philosophical', 26),\n",
       "             ('flourish', 26),\n",
       "             ('cato', 26),\n",
       "             ('throws', 26),\n",
       "             ('himself', 338),\n",
       "             ('upon', 780),\n",
       "             ('his', 3139),\n",
       "             ('sword', 78),\n",
       "             ('quietly', 78),\n",
       "             ('take', 260),\n",
       "             ('ship', 182),\n",
       "             ('there', 1456),\n",
       "             ('surprising', 26),\n",
       "             ('if', 728),\n",
       "             ('they', 728),\n",
       "             ('but', 2730),\n",
       "             ('knew', 130),\n",
       "             ('almost', 286),\n",
       "             ('all', 1872),\n",
       "             ('men', 130),\n",
       "             ('their', 390),\n",
       "             ('degree', 78),\n",
       "             ('other', 494),\n",
       "             ('cherish', 26),\n",
       "             ('very', 494),\n",
       "             ('nearly', 52),\n",
       "             ('same', 312),\n",
       "             ('feelings', 26),\n",
       "             ('towards', 260),\n",
       "             ('ocean', 52),\n",
       "             ('now', 1040),\n",
       "             ('your', 442),\n",
       "             ('insular', 26),\n",
       "             ('city', 104),\n",
       "             ('manhattoes', 26),\n",
       "             ('belted', 26),\n",
       "             ('round', 364),\n",
       "             ('by', 962),\n",
       "             ('wharves', 26),\n",
       "             ('indian', 52),\n",
       "             ('isles', 26),\n",
       "             ('coral', 26),\n",
       "             ('reefs', 26),\n",
       "             ('commerce', 26),\n",
       "             ('surrounds', 26),\n",
       "             ('her', 156),\n",
       "             ('surf', 26),\n",
       "             ('right', 156),\n",
       "             ('left', 78),\n",
       "             ('streets', 208),\n",
       "             ('you', 2236),\n",
       "             ('waterward', 52),\n",
       "             ('its', 156),\n",
       "             ('extreme', 26),\n",
       "             ('downtown', 26),\n",
       "             ('battery', 52),\n",
       "             ('where', 364),\n",
       "             ('noble', 52),\n",
       "             ('mole', 26),\n",
       "             ('washed', 52),\n",
       "             ('waves', 26),\n",
       "             ('cooled', 26),\n",
       "             ('breezes', 26),\n",
       "             ('which', 572),\n",
       "             ('few', 104),\n",
       "             ('hours', 130),\n",
       "             ('previous', 104),\n",
       "             ('were', 962),\n",
       "             ('out', 956),\n",
       "             ('sight', 104),\n",
       "             ('land', 208),\n",
       "             ('look', 156),\n",
       "             ('at', 2184),\n",
       "             ('crowds', 52),\n",
       "             ('water', 260),\n",
       "             ('gazers', 26),\n",
       "             ('circumambulate', 26),\n",
       "             ('dreamy', 26),\n",
       "             ('sabbath', 52),\n",
       "             ('afternoon', 52),\n",
       "             ('go', 494),\n",
       "             ('corlears', 26),\n",
       "             ('hook', 26),\n",
       "             ('coenties', 26),\n",
       "             ('slip', 26),\n",
       "             ('thence', 52),\n",
       "             ('whitehall', 26),\n",
       "             ('northward', 26),\n",
       "             ('what', 1170),\n",
       "             ('do', 520),\n",
       "             ('posted', 26),\n",
       "             ('like', 732),\n",
       "             ('silent', 52),\n",
       "             ('sentinels', 26),\n",
       "             ('around', 78),\n",
       "             ('town', 182),\n",
       "             ('stand', 182),\n",
       "             ('thousands', 52),\n",
       "             ('mortal', 26),\n",
       "             ('fixed', 78),\n",
       "             ('reveries', 52),\n",
       "             ('leaning', 52),\n",
       "             ('against', 234),\n",
       "             ('spiles', 26),\n",
       "             ('seated', 52),\n",
       "             ('pier', 26),\n",
       "             ('heads', 338),\n",
       "             ('looking', 312),\n",
       "             ('over', 702),\n",
       "             ('bulwarks', 52),\n",
       "             ('ships', 78),\n",
       "             ('china', 26),\n",
       "             ('aloft', 52),\n",
       "             ('rigging', 26),\n",
       "             ('striving', 26),\n",
       "             ('still', 364),\n",
       "             ('better', 208),\n",
       "             ('seaward', 26),\n",
       "             ('peep', 26),\n",
       "             ('these', 494),\n",
       "             ('are', 416),\n",
       "             ('landsmen', 26),\n",
       "             ('week', 52),\n",
       "             ('days', 104),\n",
       "             ('pent', 26),\n",
       "             ('lath', 26),\n",
       "             ('plaster', 52),\n",
       "             ('tied', 26),\n",
       "             ('counters', 26),\n",
       "             ('nailed', 26),\n",
       "             ('benches', 26),\n",
       "             ('clinched', 26),\n",
       "             ('desks', 26),\n",
       "             ('green', 130),\n",
       "             ('fields', 26),\n",
       "             ('gone', 52),\n",
       "             ('here', 624),\n",
       "             ('come', 338),\n",
       "             ('more', 494),\n",
       "             ('pacing', 26),\n",
       "             ('straight', 104),\n",
       "             ('seemingly', 26),\n",
       "             ('bound', 52),\n",
       "             ('dive', 26),\n",
       "             ('strange', 182),\n",
       "             ('will', 260),\n",
       "             ('content', 52),\n",
       "             ('them', 442),\n",
       "             ('extremest', 26),\n",
       "             ('limit', 26),\n",
       "             ('loitering', 26),\n",
       "             ('under', 260),\n",
       "             ('shady', 26),\n",
       "             ('lee', 26),\n",
       "             ('yonder', 52),\n",
       "             ('not', 1456),\n",
       "             ('suffice', 26),\n",
       "             ('must', 442),\n",
       "             ('just', 390),\n",
       "             ('nigh', 104),\n",
       "             ('possibly', 26),\n",
       "             ('without', 182),\n",
       "             ('falling', 52),\n",
       "             ('miles', 78),\n",
       "             ('leagues', 26),\n",
       "             ('inlanders', 26),\n",
       "             ('lanes', 26),\n",
       "             ('alleys', 26),\n",
       "             ('avenues', 26),\n",
       "             ('north', 52),\n",
       "             ('east', 26),\n",
       "             ('south', 156),\n",
       "             ('west', 26),\n",
       "             ('yet', 416),\n",
       "             ('unite', 26),\n",
       "             ('tell', 442),\n",
       "             ('does', 156),\n",
       "             ('magnetic', 26),\n",
       "             ('virtue', 26),\n",
       "             ('needles', 26),\n",
       "             ('compasses', 26),\n",
       "             ('those', 234),\n",
       "             ('attract', 26),\n",
       "             ('thither', 26),\n",
       "             ('once', 208),\n",
       "             ('say', 286),\n",
       "             ('country', 78),\n",
       "             ('lakes', 26),\n",
       "             ('any', 364),\n",
       "             ('path', 26),\n",
       "             ('please', 52),\n",
       "             ('ten', 52),\n",
       "             ('one', 1300),\n",
       "             ('carries', 26),\n",
       "             ('down', 468),\n",
       "             ('dale', 26),\n",
       "             ('leaves', 52),\n",
       "             ('pool', 26),\n",
       "             ('stream', 78),\n",
       "             ('magic', 52),\n",
       "             ('let', 156),\n",
       "             ('most', 468),\n",
       "             ('absent', 26),\n",
       "             ('minded', 26),\n",
       "             ('be', 1716),\n",
       "             ('plunged', 52),\n",
       "             ('deepest', 26),\n",
       "             ('man', 572),\n",
       "             ('legs', 104),\n",
       "             ('set', 156),\n",
       "             ('feet', 182),\n",
       "             ('going', 260),\n",
       "             ('he', 3299),\n",
       "             ('infallibly', 26),\n",
       "             ('lead', 78),\n",
       "             ('region', 26),\n",
       "             ('should', 286),\n",
       "             ('ever', 338),\n",
       "             ('athirst', 26),\n",
       "             ('great', 376),\n",
       "             ('american', 78),\n",
       "             ('desert', 26),\n",
       "             ('try', 104),\n",
       "             ('experiment', 26),\n",
       "             ('caravan', 26),\n",
       "             ('happen', 26),\n",
       "             ('supplied', 26),\n",
       "             ('metaphysical', 52),\n",
       "             ('professor', 26),\n",
       "             ('yes', 104),\n",
       "             ('knows', 26),\n",
       "             ('meditation', 26),\n",
       "             ('wedded', 26),\n",
       "             ('artist', 78),\n",
       "             ('desires', 26),\n",
       "             ('paint', 26),\n",
       "             ('dreamiest', 26),\n",
       "             ('shadiest', 26),\n",
       "             ('quietest', 26),\n",
       "             ('enchanting', 26),\n",
       "             ('bit', 130),\n",
       "             ('romantic', 26),\n",
       "             ('landscape', 26),\n",
       "             ('valley', 26),\n",
       "             ('saco', 26),\n",
       "             ('chief', 52),\n",
       "             ('element', 26),\n",
       "             ('employs', 26),\n",
       "             ('trees', 26),\n",
       "             ('each', 78),\n",
       "             ('hollow', 26),\n",
       "             ('trunk', 52),\n",
       "             ('hermit', 26),\n",
       "             ('crucifix', 26),\n",
       "             ('within', 130),\n",
       "             ('sleeps', 26),\n",
       "             ('meadow', 52),\n",
       "             ('sleep', 416),\n",
       "             ('cattle', 26),\n",
       "             ('cottage', 26),\n",
       "             ('goes', 78),\n",
       "             ('sleepy', 26),\n",
       "             ('smoke', 52),\n",
       "             ('deep', 78),\n",
       "             ('distant', 78),\n",
       "             ('woodlands', 26),\n",
       "             ('winds', 78),\n",
       "             ('mazy', 26),\n",
       "             ('reaching', 52),\n",
       "             ('overlapping', 26),\n",
       "             ('spurs', 26),\n",
       "             ('mountains', 26),\n",
       "             ('bathed', 26),\n",
       "             ('hill', 52),\n",
       "             ('side', 286),\n",
       "             ('blue', 78),\n",
       "             ('though', 546),\n",
       "             ('picture', 130),\n",
       "             ('lies', 26),\n",
       "             ('thus', 52),\n",
       "             ('tranced', 26),\n",
       "             ('pine', 52),\n",
       "             ('tree', 26),\n",
       "             ('shakes', 26),\n",
       "             ('sighs', 52),\n",
       "             ('shepherd', 52),\n",
       "             ('head', 624),\n",
       "             ('vain', 26),\n",
       "             ('unless', 104),\n",
       "             ('eye', 26),\n",
       "             ('him', 1118),\n",
       "             ('visit', 26),\n",
       "             ('prairies', 26),\n",
       "             ('june', 52),\n",
       "             ('when', 650),\n",
       "             ('scores', 52),\n",
       "             ('wade', 26),\n",
       "             ('knee', 26),\n",
       "             ('among', 78),\n",
       "             ('tiger', 26),\n",
       "             ('lilies', 26),\n",
       "             ('charm', 26),\n",
       "             ('wanting', 26),\n",
       "             ('drop', 26),\n",
       "             ('niagara', 26),\n",
       "             ('cataract', 26),\n",
       "             ('sand', 26),\n",
       "             ('travel', 26),\n",
       "             ('thousand', 52),\n",
       "             ('why', 286),\n",
       "             ('did', 494),\n",
       "             ('poor', 104),\n",
       "             ('poet', 26),\n",
       "             ('tennessee', 26),\n",
       "             ('suddenly', 78),\n",
       "             ('receiving', 26),\n",
       "             ('two', 338),\n",
       "             ('handfuls', 26),\n",
       "             ('silver', 52),\n",
       "             ('deliberate', 26),\n",
       "             ('whether', 182),\n",
       "             ('buy', 26),\n",
       "             ('coat', 104),\n",
       "             ('sadly', 52),\n",
       "             ('needed', 26),\n",
       "             ('invest', 26),\n",
       "             ('pedestrian', 26),\n",
       "             ('trip', 26),\n",
       "             ('rockaway', 26),\n",
       "             ('beach', 26),\n",
       "             ('robust', 52),\n",
       "             ('healthy', 52),\n",
       "             ('boy', 52),\n",
       "             ('crazy', 52),\n",
       "             ('first', 494),\n",
       "             ('voyage', 208),\n",
       "             ('passenger', 104),\n",
       "             ('yourself', 156),\n",
       "             ('feel', 78),\n",
       "             ('mystical', 26),\n",
       "             ('vibration', 26),\n",
       "             ('told', 130),\n",
       "             ('old', 754),\n",
       "             ('persians', 26),\n",
       "             ('hold', 52),\n",
       "             ('holy', 52),\n",
       "             ('greeks', 26),\n",
       "             ('give', 208),\n",
       "             ('separate', 26),\n",
       "             ('deity', 26),\n",
       "             ('own', 286),\n",
       "             ('brother', 52),\n",
       "             ('jove', 26),\n",
       "             ('surely', 26),\n",
       "             ('meaning', 78),\n",
       "             ('deeper', 26),\n",
       "             ('story', 130),\n",
       "             ('narcissus', 26),\n",
       "             ('who', 416),\n",
       "             ('because', 182),\n",
       "             ('could', 572),\n",
       "             ('grasp', 26),\n",
       "             ('tormenting', 26),\n",
       "             ('mild', 26),\n",
       "             ('image', 156),\n",
       "             ('saw', 156),\n",
       "             ('fountain', 26),\n",
       "             ('was', 2886),\n",
       "             ('drowned', 26),\n",
       "             ('we', 286),\n",
       "             ('ourselves', 52),\n",
       "             ('rivers', 26),\n",
       "             ('oceans', 26),\n",
       "             ('ungraspable', 26),\n",
       "             ('phantom', 78),\n",
       "             ('life', 78),\n",
       "             ('key', 26),\n",
       "             ('am', 156),\n",
       "             ('habit', 26),\n",
       "             ('begin', 52),\n",
       "             ('grow', 52),\n",
       "             ('hazy', 26),\n",
       "             ('eyes', 182),\n",
       "             ('conscious', 26),\n",
       "             ('lungs', 26),\n",
       "             ('mean', 130),\n",
       "             ('inferred', 52),\n",
       "             ('needs', 52),\n",
       "             ('rag', 26),\n",
       "             ('something', 312),\n",
       "             ('besides', 156),\n",
       "             ('passengers', 78),\n",
       "             ('sick', 26),\n",
       "             ('quarrelsome', 26),\n",
       "             ('don', 234),\n",
       "             ('t', 728),\n",
       "             ('nights', 26),\n",
       "             ('enjoy', 26),\n",
       "             ('themselves', 52),\n",
       "             ('much', 442),\n",
       "             ('general', 26),\n",
       "             ('thing', 130),\n",
       "             ('nor', 78),\n",
       "             ('salt', 26),\n",
       "             ('commodore', 52),\n",
       "             ('captain', 52),\n",
       "             ('cook', 78),\n",
       "             ('abandon', 26),\n",
       "             ('glory', 52),\n",
       "             ('distinction', 26),\n",
       "             ('offices', 26),\n",
       "             ('abominate', 26),\n",
       "             ('honourable', 26),\n",
       "             ('respectable', 26),\n",
       "             ('toils', 26),\n",
       "             ('trials', 26),\n",
       "             ('tribulations', 26),\n",
       "             ('kind', 78),\n",
       "             ('whatsoever', 52),\n",
       "             ('quite', 78),\n",
       "             ('care', 78),\n",
       "             ('taking', 104),\n",
       "             ('barques', 26),\n",
       "             ('brigs', 26),\n",
       "             ('schooners', 26),\n",
       "             ('confess', 52),\n",
       "             ('considerable', 26),\n",
       "             ('being', 390),\n",
       "             ('sort', 494),\n",
       "             ('officer', 52),\n",
       "             ('board', 78),\n",
       "             ('somehow', 78),\n",
       "             ('fancied', 26),\n",
       "             ('broiling', 26),\n",
       "             ('fowls', 26),\n",
       "             ('broiled', 78),\n",
       "             ('judiciously', 26),\n",
       "             ('buttered', 26),\n",
       "             ('judgmatically', 26),\n",
       "             ('salted', 26),\n",
       "             ('peppered', 26),\n",
       "             ('speak', 130),\n",
       "             ('respectfully', 52),\n",
       "             ('reverentially', 26),\n",
       "             ('fowl', 26),\n",
       "             ('than', 390),\n",
       "             ('idolatrous', 26),\n",
       "             ('dotings', 26),\n",
       "             ('egyptians', 26),\n",
       "             ('ibis', 26),\n",
       "             ('roasted', 26),\n",
       "             ('river', 26),\n",
       "             ('horse', 52),\n",
       "             ('mummies', 26),\n",
       "             ('creatures', 26),\n",
       "             ('huge', 52),\n",
       "             ('bake', 26),\n",
       "             ('houses', 52),\n",
       "             ('pyramids', 26),\n",
       "             ('simple', 26),\n",
       "             ('sailor', 156),\n",
       "             ('mast', 78),\n",
       "             ('plumb', 26),\n",
       "             ('forecastle', 52),\n",
       "             ('royal', 26),\n",
       "             ('true', 104),\n",
       "             ('rather', 260),\n",
       "             ('order', 130),\n",
       "             ('make', 260),\n",
       "             ('jump', 52),\n",
       "             ('spar', 52),\n",
       "             ('grasshopper', 26),\n",
       "             ('may', 312),\n",
       "             ('unpleasant', 26),\n",
       "             ('enough', 338),\n",
       "             ('touches', 26),\n",
       "             ('sense', 78),\n",
       "             ('honour', 26),\n",
       "             ('particularly', 52),\n",
       "             ('established', 26),\n",
       "             ('family', 26),\n",
       "             ('van', 26),\n",
       "             ('rensselaers', 26),\n",
       "             ('randolphs', 26),\n",
       "             ('hardicanutes', 26),\n",
       "             ('putting', 52),\n",
       "             ('tar', 52),\n",
       "             ('pot', 26),\n",
       "             ('been', 468),\n",
       "             ('lording', 26),\n",
       "             ('schoolmaster', 52),\n",
       "             ('making', 130),\n",
       "             ('tallest', 26),\n",
       "             ('boys', 52),\n",
       "             ('awe', 26),\n",
       "             ('transition', 52),\n",
       "             ('keen', 26),\n",
       "             ('assure', 26),\n",
       "             ('decoction', 26),\n",
       "             ('seneca', 26),\n",
       "             ('stoics', 26),\n",
       "             ('enable', 26),\n",
       "             ('grin', 52),\n",
       "             ('bear', 52),\n",
       "             ('even', 130),\n",
       "             ('wears', 26),\n",
       "             ('hunks', 52),\n",
       "             ('orders', 26),\n",
       "             ('broom', 26),\n",
       "             ('sweep', 52),\n",
       "             ('decks', 26),\n",
       "             ('indignity', 26),\n",
       "             ('amount', 26),\n",
       "             ('weighed', 52),\n",
       "             ('scales', 26),\n",
       "             ('new', 286),\n",
       "             ('testament', 26),\n",
       "             ('think', 182),\n",
       "             ('archangel', 26),\n",
       "             ('gabriel', 26),\n",
       "             ('thinks', 182),\n",
       "             ('anything', 52),\n",
       "             ('less', 52),\n",
       "             ('promptly', 26),\n",
       "             ('obey', 26),\n",
       "             ('instance', 26),\n",
       "             ('ain', 78),\n",
       "             ('slave', 26),\n",
       "             ('well', 208),\n",
       "             ('however', 208),\n",
       "             ('captains', 26),\n",
       "             ('thump', 52),\n",
       "             ('punch', 26),\n",
       "             ('satisfaction', 26),\n",
       "             ('knowing', 78),\n",
       "             ('everybody', 26),\n",
       "             ('else', 208),\n",
       "             ('served', 26),\n",
       "             ('either', 78),\n",
       "             ('physical', 26),\n",
       "             ('point', 52),\n",
       "             ('view', 52),\n",
       "             ('so', 1092),\n",
       "             ('universal', 26),\n",
       "             ('passed', 78),\n",
       "             ('hands', 78),\n",
       "             ('rub', 26),\n",
       "             ('shoulder', 26),\n",
       "             ('blades', 26),\n",
       "             ('again', 286),\n",
       "             ('always', 104),\n",
       "             ('paying', 78),\n",
       "             ('trouble', 26),\n",
       "             ('whereas', 26),\n",
       "             ('pay', 78),\n",
       "             ('single', 52),\n",
       "             ('penny', 78),\n",
       "             ('heard', 208),\n",
       "             ('contrary', 26),\n",
       "             ('difference', 52),\n",
       "             ('between', 234),\n",
       "             ('paid', 52),\n",
       "             ('act', 52),\n",
       "             ('perhaps', 130),\n",
       "             ('uncomfortable', 52),\n",
       "             ('infliction', 26),\n",
       "             ('orchard', 26),\n",
       "             ('thieves', 26),\n",
       "             ('entailed', 26),\n",
       "             ('us', 104),\n",
       "             ('compare', 52),\n",
       "             ('urbane', 26),\n",
       "             ('activity', 26),\n",
       "             ('receives', 26),\n",
       "             ('really', 104),\n",
       "             ('marvellous', 104),\n",
       "             ('considering', 26),\n",
       "             ('earnestly', 26),\n",
       "             ('believe', 26),\n",
       "             ('root', 26),\n",
       "             ('earthly', 52),\n",
       "             ('ills', 26),\n",
       "             ('monied', 26),\n",
       "             ('enter', 52),\n",
       "             ('heaven', 104),\n",
       "             ('ah', 26),\n",
       "             ('cheerfully', 26),\n",
       "             ('consign', 26),\n",
       "             ('perdition', 26),\n",
       "             ('finally', 26),\n",
       "             ('wholesome', 26),\n",
       "             ('exercise', 26),\n",
       "             ('pure', 26),\n",
       "             ('air', 104),\n",
       "             ('fore', 26),\n",
       "             ('castle', 26),\n",
       "             ('deck', 52),\n",
       "             ('far', 104),\n",
       "             ('prevalent', 26),\n",
       "             ('astern', 26),\n",
       "             ('violate', 26),\n",
       "             ('pythagorean', 26),\n",
       "             ('maxim', 26),\n",
       "             ('quarter', 52),\n",
       "             ('gets', 26),\n",
       "             ('atmosphere', 26),\n",
       "             ('second', 104),\n",
       "             ('sailors', 78),\n",
       "             ('breathes', 26),\n",
       "             ('commonalty', 26),\n",
       "             ('leaders', 52),\n",
       "             ('many', 104),\n",
       "             ('things', 130),\n",
       "             ('suspect', 26),\n",
       "             ('wherefore', 26),\n",
       "             ('after', 234),\n",
       "             ('repeatedly', 26),\n",
       "             ('smelt', 52),\n",
       "             ('merchant', 26),\n",
       "             ('whaling', 234),\n",
       "             ('invisible', 26),\n",
       "             ('police', 26),\n",
       "             ('fates', 52),\n",
       "             ('has', 104),\n",
       "             ('constant', 26),\n",
       "             ('surveillance', 26),\n",
       "             ('secretly', 26),\n",
       "             ('dogs', 26),\n",
       "             ('influences', 26),\n",
       "             ('unaccountable', 104),\n",
       "             ('answer', 130),\n",
       "             ('doubtless', 52),\n",
       "             ('formed', 52),\n",
       "             ('grand', 104),\n",
       "             ('programme', 26),\n",
       "             ('providence', 26),\n",
       "             ('drawn', 26),\n",
       "             ('came', 286),\n",
       "             ('brief', 26),\n",
       "             ('interlude', 26),\n",
       "             ('solo', 26),\n",
       "             ('extensive', 26),\n",
       "             ('performances', 26),\n",
       "             ('bill', 26),\n",
       "             ('run', 52),\n",
       "             ('contested', 26),\n",
       "             ('election', 26),\n",
       "             ('presidency', 26),\n",
       "             ('united', 26),\n",
       "             ('states', 26),\n",
       "             ('bloody', 26),\n",
       "             ('battle', 26),\n",
       "             ('affghanistan', 26),\n",
       "             ('cannot', 78),\n",
       "             ('exactly', 78),\n",
       "             ('stage', 52),\n",
       "             ('managers', 26),\n",
       "             ('put', 208),\n",
       "             ('shabby', 52),\n",
       "             ('others', 52),\n",
       "             ('magnificent', 26),\n",
       "             ('parts', 130),\n",
       "             ('tragedies', 26),\n",
       "             ('short', 78),\n",
       "             ('easy', 78),\n",
       "             ('genteel', 26),\n",
       "             ('comedies', 26),\n",
       "             ('jolly', 104),\n",
       "             ('farces', 26),\n",
       "             ('recall', 26),\n",
       "             ('circumstances', 52),\n",
       "             ('springs', 26),\n",
       "             ('motives', 52),\n",
       "             ('cunningly', 26),\n",
       "             ('presented', 26),\n",
       "             ('various', 52),\n",
       "             ('disguises', 26),\n",
       "             ('induced', 26),\n",
       "             ('performing', 26),\n",
       "             ('cajoling', 26),\n",
       "             ('delusion', 26),\n",
       "             ('choice', 26),\n",
       "             ('resulting', 26),\n",
       "             ('unbiased', 26),\n",
       "             ('freewill', 26),\n",
       "             ('discriminating', 26),\n",
       "             ('judgment', 26),\n",
       "             ('overwhelming', 26),\n",
       "             ('idea', 182),\n",
       "             ('whale', 260),\n",
       "             ('portentous', 78),\n",
       "             ('mysterious', 52),\n",
       "             ('monster', 26),\n",
       "             ('roused', 26),\n",
       "             ('curiosity', 52),\n",
       "             ('wild', 130),\n",
       "             ('seas', 156),\n",
       "             ('rolled', 156),\n",
       "             ('island', 78),\n",
       "             ('bulk', 26),\n",
       "             ('undeliverable', 26),\n",
       "             ('nameless', 78),\n",
       "             ('perils', 26),\n",
       "             ('attending', 26),\n",
       "             ('marvels', 26),\n",
       "             ('patagonian', 26),\n",
       "             ('sights', 26),\n",
       "             ('sounds', 78),\n",
       "             ('helped', 26),\n",
       "             ('sway', 26),\n",
       "             ('wish', 26),\n",
       "             ('inducements', 26),\n",
       "             ('tormented', 52),\n",
       "             ('everlasting', 52),\n",
       "             ('itch', 26),\n",
       "             ('remote', 26),\n",
       "             ('love', 26),\n",
       "             ('forbidden', 26),\n",
       "             ('barbarous', 26),\n",
       "             ('coasts', 26),\n",
       "             ('ignoring', 26),\n",
       "             ('good', 442),\n",
       "             ('quick', 26),\n",
       "             ('perceive', 26),\n",
       "             ('horror', 26),\n",
       "             ('social', 26),\n",
       "             ('since', 78),\n",
       "             ('friendly', 26),\n",
       "             ('terms', 26),\n",
       "             ('inmates', 26),\n",
       "             ('place', 390),\n",
       "             ('lodges', 26),\n",
       "             ('reason', 130),\n",
       "             ('welcome', 26),\n",
       "             ('flood', 26),\n",
       "             ('gates', 26),\n",
       "             ('wonder', 52),\n",
       "             ('swung', 26),\n",
       "             ('open', 104),\n",
       "             ('conceits', 26),\n",
       "             ('swayed', 26),\n",
       "             ('purpose', 52),\n",
       "             ('floated', 52),\n",
       "             ('inmost', 26),\n",
       "             ('endless', 26),\n",
       "             ('processions', 26),\n",
       "             ('mid', 26),\n",
       "             ('hooded', 26),\n",
       "             ('snow', 78),\n",
       "             ('stuffed', 52),\n",
       "             ('shirt', 104),\n",
       "             ('carpet', 26),\n",
       "             ('bag', 182),\n",
       "             ('tucked', 26),\n",
       "             ('arm', 286),\n",
       "             ('started', 26),\n",
       "             ('cape', 104),\n",
       "             ('horn', 52),\n",
       "             ('pacific', 26),\n",
       "             ('quitting', 26),\n",
       "             ('manhatto', 26),\n",
       "             ('duly', 26),\n",
       "             ('arrived', 52),\n",
       "             ('bedford', 104),\n",
       "             ('saturday', 78),\n",
       "             ('night', 624),\n",
       "             ('december', 26),\n",
       "             ('disappointed', 26),\n",
       "             ('learning', 26),\n",
       "             ('packet', 26),\n",
       "             ('nantucket', 182),\n",
       "             ('had', 858),\n",
       "             ('already', 26),\n",
       "             ('sailed', 26),\n",
       "             ('offer', 52),\n",
       "             ('till', 156),\n",
       "             ('following', 52),\n",
       "             ('monday', 26),\n",
       "             ('young', 130),\n",
       "             ('candidates', 26),\n",
       "             ('pains', 26),\n",
       "             ('penalties', 26),\n",
       "             ('stop', 208),\n",
       "             ('embark', 52),\n",
       "             ('related', 26),\n",
       "             ('doing', 26),\n",
       "             ('made', 338),\n",
       "             ('craft', 130),\n",
       "             ('fine', 104),\n",
       "             ('boisterous', 26),\n",
       "             ('everything', 26),\n",
       "             ('connected', 26),\n",
       "             ('famous', 26),\n",
       "             ('amazingly', 26),\n",
       "             ('pleased', 52),\n",
       "             ('late', 182),\n",
       "             ('gradually', 26),\n",
       "             ('monopolising', 26),\n",
       "             ('business', 130),\n",
       "             ('matter', 78),\n",
       "             ('behind', 26),\n",
       "             ('original', 52),\n",
       "             ('tyre', 26),\n",
       "             ('carthage', 26),\n",
       "             ('dead', 130),\n",
       "             ('stranded', 52),\n",
       "             ('aboriginal', 26),\n",
       "             ('whalemen', 26),\n",
       "             ('red', 78),\n",
       "             ('sally', 26),\n",
       "             ('canoes', 26),\n",
       "             ('chase', 26),\n",
       "             ('leviathan', 52),\n",
       "             ('too', 364),\n",
       "             ('adventurous', 26),\n",
       "             ('sloop', 26),\n",
       "             ('forth', 26),\n",
       "             ('partly', 78),\n",
       "             ('laden', 26),\n",
       "             ('imported', 26),\n",
       "             ('cobblestones', 26),\n",
       "             ('throw', 26),\n",
       "             ('whales', 52),\n",
       "             ('discover', 26),\n",
       "             ('risk', 26),\n",
       "             ('harpoon', 135),\n",
       "             ('bowsprit', 26),\n",
       "             ('day', 156),\n",
       "             ('another', 130),\n",
       "             ('ere', 78),\n",
       "             ('destined', 26),\n",
       "             ('port', 26),\n",
       "             ('became', 78),\n",
       "             ('concernment', 26),\n",
       "             ('eat', 26),\n",
       "             ('meanwhile', 78),\n",
       "             ('dubious', 26),\n",
       "             ('nay', 52),\n",
       "             ('dark', 208),\n",
       "             ('dismal', 52),\n",
       "             ('bitingly', 26),\n",
       "             ('cold', 182),\n",
       "             ('cheerless', 26),\n",
       "             ('anxious', 26),\n",
       "             ('grapnels', 26),\n",
       "             ('sounded', 26),\n",
       "             ('pocket', 78),\n",
       "             ('only', 364),\n",
       "             ('brought', 26),\n",
       "             ('pieces', 26),\n",
       "             ('wherever', 52),\n",
       "             ('said', 520),\n",
       "             ('stood', 260),\n",
       "             ('middle', 130),\n",
       "             ('dreary', 52),\n",
       "             ('shouldering', 26),\n",
       "             ('comparing', 26),\n",
       "             ('gloom', 26),\n",
       "             ('darkness', 78),\n",
       "             ('wisdom', 26),\n",
       "             ('conclude', 26),\n",
       "             ('lodge', 26),\n",
       "             ('dear', 26),\n",
       "             ('sure', 130),\n",
       "             ('inquire', 26),\n",
       "             ('price', 26),\n",
       "             ('halting', 26),\n",
       "             ('steps', 26),\n",
       "             ('paced', 26),\n",
       "             ('sign', 156),\n",
       "             ('crossed', 52),\n",
       "             ('harpoons', 78),\n",
       "             ('looked', 156),\n",
       "             ('expensive', 52),\n",
       "             ('further', 104),\n",
       "             ('bright', 52),\n",
       "             ('windows', 52),\n",
       "             ('fish', 104),\n",
       "             ('inn', 104),\n",
       "             ('fervent', 26),\n",
       "             ('rays', 26),\n",
       "             ('seemed', 416),\n",
       "             ('melted', 26),\n",
       "             ('packed', 52),\n",
       "             ('ice', 104),\n",
       "             ('house', 286),\n",
       "             ('everywhere', 26),\n",
       "             ('congealed', 26),\n",
       "             ('frost', 104),\n",
       "             ('lay', 234),\n",
       "             ('inches', 52),\n",
       "             ('thick', 52),\n",
       "             ('hard', 156),\n",
       "             ('asphaltic', 26),\n",
       "             ('pavement', 26),\n",
       "             ...])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2695"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO KNOW THE NO> OF UNIQUE WORDS IN OUR TEXT FILE\n",
    "vocabulary_size=len(tokenizer.word_counts)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 960,   14,  263, ..., 2690,   14,   25],\n",
       "       [  14,  263,   51, ...,   14,   25,  961],\n",
       "       [ 263,   51,  261, ...,   25,  961,    5],\n",
       "       ...,\n",
       "       [ 956,   12,  167, ...,  262,   53,    2],\n",
       "       [  12,  167, 2689, ...,   53,    2, 2695],\n",
       "       [ 167, 2689,    3, ...,    2, 2695,   24]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##NOW CONVERT THE SEQUENCES(LIST JEYTA) TO NP.ARRAY\n",
    "import numpy as np\n",
    "seq=np.array(sequences)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIME TO MAKE THE X and Y LABELS\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x=seq[:,:-1] #make first 24 words as train and the last word as label in every case\n",
    "y=seq[:,-1]\n",
    "\n",
    "#make label to_categorical\n",
    "y=to_categorical(y, num_classes=vocabulary_size+1) ##the +1 is needed as it is the way keras padding works to hold an extra zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=x.shape[1]  # basically koita kore word thakbe ekekta sequence e, here 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            67400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 150)           105600    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 150)               180600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2696)              407096    \n",
      "=================================================================\n",
      "Total params: 783,346\n",
      "Trainable params: 783,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MODEL\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "\n",
    "def create_model(vocabulary_size, sequence_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, sequence_length, input_length=sequence_length))\n",
    "    model.add(LSTM(150, return_sequences=True)) ##No of neurons in LSTM is generally multiples of sequence_length\n",
    "    model.add(LSTM(150))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(vocabulary_size+1, sequence_length) #+1 is because of the way embedding layer works with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11345/11345 [==============================] - 10s 899us/step - loss: 6.2225 - accuracy: 0.0529\n",
      "Epoch 2/100\n",
      "11345/11345 [==============================] - 10s 873us/step - loss: 6.1250 - accuracy: 0.0531\n",
      "Epoch 3/100\n",
      "11345/11345 [==============================] - 9s 816us/step - loss: 6.0434 - accuracy: 0.0600\n",
      "Epoch 4/100\n",
      "11345/11345 [==============================] - 9s 824us/step - loss: 5.9069 - accuracy: 0.0663\n",
      "Epoch 5/100\n",
      "11345/11345 [==============================] - 9s 786us/step - loss: 5.8124 - accuracy: 0.0659\n",
      "Epoch 6/100\n",
      "11345/11345 [==============================] - 9s 825us/step - loss: 5.7533 - accuracy: 0.0681\n",
      "Epoch 7/100\n",
      "11345/11345 [==============================] - 10s 848us/step - loss: 5.6679 - accuracy: 0.0718\n",
      "Epoch 8/100\n",
      "11345/11345 [==============================] - 9s 822us/step - loss: 5.5908 - accuracy: 0.0748\n",
      "Epoch 9/100\n",
      "11345/11345 [==============================] - 9s 814us/step - loss: 5.5181 - accuracy: 0.0769\n",
      "Epoch 10/100\n",
      "11345/11345 [==============================] - 9s 831us/step - loss: 5.4525 - accuracy: 0.0801\n",
      "Epoch 11/100\n",
      "11345/11345 [==============================] - 9s 818us/step - loss: 5.3829 - accuracy: 0.0819\n",
      "Epoch 12/100\n",
      "11345/11345 [==============================] - 9s 780us/step - loss: 5.3155 - accuracy: 0.0839\n",
      "Epoch 13/100\n",
      "11345/11345 [==============================] - 9s 775us/step - loss: 5.2515 - accuracy: 0.0850\n",
      "Epoch 14/100\n",
      "11345/11345 [==============================] - 9s 795us/step - loss: 5.1895 - accuracy: 0.0871\n",
      "Epoch 15/100\n",
      "11345/11345 [==============================] - 9s 815us/step - loss: 5.1245 - accuracy: 0.0880\n",
      "Epoch 16/100\n",
      "11345/11345 [==============================] - 9s 814us/step - loss: 5.0594 - accuracy: 0.0910\n",
      "Epoch 17/100\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 5.0076 - accuracy: 0.0918\n",
      "Epoch 18/100\n",
      "11345/11345 [==============================] - 9s 798us/step - loss: 4.9466 - accuracy: 0.0959\n",
      "Epoch 19/100\n",
      "11345/11345 [==============================] - 9s 828us/step - loss: 4.8995 - accuracy: 0.0967\n",
      "Epoch 20/100\n",
      "11345/11345 [==============================] - 9s 794us/step - loss: 4.8383 - accuracy: 0.0970\n",
      "Epoch 21/100\n",
      "11345/11345 [==============================] - 9s 798us/step - loss: 4.7838 - accuracy: 0.0981\n",
      "Epoch 22/100\n",
      "11345/11345 [==============================] - 9s 771us/step - loss: 4.7371 - accuracy: 0.1002\n",
      "Epoch 23/100\n",
      "11345/11345 [==============================] - 9s 776us/step - loss: 4.6857 - accuracy: 0.1012\n",
      "Epoch 24/100\n",
      "11345/11345 [==============================] - 9s 775us/step - loss: 4.6344 - accuracy: 0.1048\n",
      "Epoch 25/100\n",
      "11345/11345 [==============================] - 9s 793us/step - loss: 4.5980 - accuracy: 0.1036\n",
      "Epoch 26/100\n",
      "11345/11345 [==============================] - 9s 799us/step - loss: 4.5423 - accuracy: 0.1073\n",
      "Epoch 27/100\n",
      "11345/11345 [==============================] - 9s 776us/step - loss: 4.4959 - accuracy: 0.1112\n",
      "Epoch 28/100\n",
      "11345/11345 [==============================] - 9s 789us/step - loss: 4.4518 - accuracy: 0.1104\n",
      "Epoch 29/100\n",
      "11345/11345 [==============================] - 9s 804us/step - loss: 4.4080 - accuracy: 0.1112\n",
      "Epoch 30/100\n",
      "11345/11345 [==============================] - 9s 793us/step - loss: 4.3657 - accuracy: 0.1135\n",
      "Epoch 31/100\n",
      "11345/11345 [==============================] - 9s 800us/step - loss: 4.3224 - accuracy: 0.1137\n",
      "Epoch 32/100\n",
      "11345/11345 [==============================] - 9s 828us/step - loss: 4.2775 - accuracy: 0.1195\n",
      "Epoch 33/100\n",
      "11345/11345 [==============================] - 9s 831us/step - loss: 4.2345 - accuracy: 0.1169\n",
      "Epoch 34/100\n",
      "11345/11345 [==============================] - 9s 808us/step - loss: 4.2038 - accuracy: 0.1201\n",
      "Epoch 35/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 4.1635 - accuracy: 0.1235\n",
      "Epoch 36/100\n",
      "11345/11345 [==============================] - 9s 776us/step - loss: 4.1158 - accuracy: 0.1276\n",
      "Epoch 37/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 4.0810 - accuracy: 0.1255\n",
      "Epoch 38/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 4.0465 - accuracy: 0.1318\n",
      "Epoch 39/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 4.0037 - accuracy: 0.1323\n",
      "Epoch 40/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.9744 - accuracy: 0.1328\n",
      "Epoch 41/100\n",
      "11345/11345 [==============================] - 9s 772us/step - loss: 3.9323 - accuracy: 0.1414\n",
      "Epoch 42/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.9060 - accuracy: 0.1403\n",
      "Epoch 43/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 3.8612 - accuracy: 0.1454\n",
      "Epoch 44/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.8203 - accuracy: 0.1465\n",
      "Epoch 45/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.7866 - accuracy: 0.1535\n",
      "Epoch 46/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.7517 - accuracy: 0.1542\n",
      "Epoch 47/100\n",
      "11345/11345 [==============================] - 9s 775us/step - loss: 3.7177 - accuracy: 0.1568\n",
      "Epoch 48/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.6879 - accuracy: 0.1654\n",
      "Epoch 49/100\n",
      "11345/11345 [==============================] - 9s 773us/step - loss: 3.6627 - accuracy: 0.1653\n",
      "Epoch 50/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 3.6241 - accuracy: 0.1654\n",
      "Epoch 51/100\n",
      "11345/11345 [==============================] - 9s 793us/step - loss: 3.5963 - accuracy: 0.1737\n",
      "Epoch 52/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 3.5545 - accuracy: 0.1781\n",
      "Epoch 53/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 3.5287 - accuracy: 0.1862\n",
      "Epoch 54/100\n",
      "11345/11345 [==============================] - 9s 777us/step - loss: 3.5072 - accuracy: 0.1858\n",
      "Epoch 55/100\n",
      "11345/11345 [==============================] - 9s 774us/step - loss: 3.4625 - accuracy: 0.1874\n",
      "Epoch 56/100\n",
      "11345/11345 [==============================] - 9s 829us/step - loss: 3.4290 - accuracy: 0.1952\n",
      "Epoch 57/100\n",
      "11345/11345 [==============================] - 10s 881us/step - loss: 3.4018 - accuracy: 0.1990\n",
      "Epoch 58/100\n",
      "11345/11345 [==============================] - 10s 867us/step - loss: 3.3785 - accuracy: 0.2073\n",
      "Epoch 59/100\n",
      "11345/11345 [==============================] - 9s 807us/step - loss: 3.3385 - accuracy: 0.2136\n",
      "Epoch 60/100\n",
      "11345/11345 [==============================] - 9s 778us/step - loss: 3.3095 - accuracy: 0.2144\n",
      "Epoch 61/100\n",
      "11345/11345 [==============================] - 9s 790us/step - loss: 3.2819 - accuracy: 0.2210\n",
      "Epoch 62/100\n",
      "11345/11345 [==============================] - 10s 874us/step - loss: 3.2583 - accuracy: 0.2259\n",
      "Epoch 63/100\n",
      "11345/11345 [==============================] - 9s 811us/step - loss: 3.2306 - accuracy: 0.2286\n",
      "Epoch 64/100\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 3.1910 - accuracy: 0.2354\n",
      "Epoch 65/100\n",
      "11345/11345 [==============================] - 9s 816us/step - loss: 3.1614 - accuracy: 0.2412\n",
      "Epoch 66/100\n",
      "11345/11345 [==============================] - 10s 890us/step - loss: 3.1456 - accuracy: 0.2449\n",
      "Epoch 67/100\n",
      "11345/11345 [==============================] - 9s 798us/step - loss: 3.1122 - accuracy: 0.2480\n",
      "Epoch 68/100\n",
      "11345/11345 [==============================] - 9s 800us/step - loss: 3.0820 - accuracy: 0.2546\n",
      "Epoch 69/100\n",
      "11345/11345 [==============================] - 9s 834us/step - loss: 3.0544 - accuracy: 0.2591\n",
      "Epoch 70/100\n",
      "11345/11345 [==============================] - 10s 871us/step - loss: 3.0358 - accuracy: 0.2614\n",
      "Epoch 71/100\n",
      "11345/11345 [==============================] - 9s 829us/step - loss: 3.0129 - accuracy: 0.2672\n",
      "Epoch 72/100\n",
      "11345/11345 [==============================] - 9s 831us/step - loss: 2.9705 - accuracy: 0.2745\n",
      "Epoch 73/100\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 2.9517 - accuracy: 0.2816\n",
      "Epoch 74/100\n",
      "11345/11345 [==============================] - 9s 828us/step - loss: 2.9318 - accuracy: 0.2814\n",
      "Epoch 75/100\n",
      "11345/11345 [==============================] - 9s 828us/step - loss: 2.9144 - accuracy: 0.2826\n",
      "Epoch 76/100\n",
      "11345/11345 [==============================] - 9s 824us/step - loss: 2.8811 - accuracy: 0.2914\n",
      "Epoch 77/100\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 2.8562 - accuracy: 0.2944\n",
      "Epoch 78/100\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 2.8346 - accuracy: 0.3042\n",
      "Epoch 79/100\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 2.8196 - accuracy: 0.3067\n",
      "Epoch 80/100\n",
      "11345/11345 [==============================] - 10s 846us/step - loss: 2.7889 - accuracy: 0.3083\n",
      "Epoch 81/100\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 2.7597 - accuracy: 0.3204\n",
      "Epoch 82/100\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 2.7355 - accuracy: 0.3265\n",
      "Epoch 83/100\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 2.7075 - accuracy: 0.3303\n",
      "Epoch 84/100\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 2.6922 - accuracy: 0.3299\n",
      "Epoch 85/100\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 2.6636 - accuracy: 0.3403\n",
      "Epoch 86/100\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 2.6505 - accuracy: 0.3404\n",
      "Epoch 87/100\n",
      "11345/11345 [==============================] - 10s 849us/step - loss: 2.6358 - accuracy: 0.3395\n",
      "Epoch 88/100\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 2.6087 - accuracy: 0.3459\n",
      "Epoch 89/100\n",
      "11345/11345 [==============================] - 10s 855us/step - loss: 2.5821 - accuracy: 0.3519\n",
      "Epoch 90/100\n",
      "11345/11345 [==============================] - 10s 853us/step - loss: 2.5609 - accuracy: 0.3628\n",
      "Epoch 91/100\n",
      "11345/11345 [==============================] - 10s 890us/step - loss: 2.5531 - accuracy: 0.3580\n",
      "Epoch 92/100\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 2.5217 - accuracy: 0.3660\n",
      "Epoch 93/100\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 2.4985 - accuracy: 0.3706\n",
      "Epoch 94/100\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 2.4820 - accuracy: 0.3781\n",
      "Epoch 95/100\n",
      "11345/11345 [==============================] - 10s 855us/step - loss: 2.4556 - accuracy: 0.3850\n",
      "Epoch 96/100\n",
      "11345/11345 [==============================] - 11s 940us/step - loss: 2.4400 - accuracy: 0.3865\n",
      "Epoch 97/100\n",
      "11345/11345 [==============================] - 11s 933us/step - loss: 2.4261 - accuracy: 0.3871\n",
      "Epoch 98/100\n",
      "11345/11345 [==============================] - 10s 922us/step - loss: 2.4180 - accuracy: 0.3855\n",
      "Epoch 99/100\n",
      "11345/11345 [==============================] - 10s 869us/step - loss: 2.3868 - accuracy: 0.3999\n",
      "Epoch 100/100\n",
      "11345/11345 [==============================] - 10s 914us/step - loss: 2.3692 - accuracy: 0.3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x214c8e60c48>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('epoch100.h5')\n",
    "# save the tokenizer\n",
    "from pickle import dump,load\n",
    "dump(tokenizer, open('my_token', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 2.3667 - accuracy: 0.3974\n",
      "Epoch 2/300\n",
      "11345/11345 [==============================] - 10s 849us/step - loss: 2.3399 - accuracy: 0.4034\n",
      "Epoch 3/300\n",
      "11345/11345 [==============================] - 10s 849us/step - loss: 2.3254 - accuracy: 0.4019\n",
      "Epoch 4/300\n",
      "11345/11345 [==============================] - 10s 853us/step - loss: 2.2997 - accuracy: 0.4146\n",
      "Epoch 5/300\n",
      "11345/11345 [==============================] - 10s 851us/step - loss: 2.2770 - accuracy: 0.4197\n",
      "Epoch 6/300\n",
      "11345/11345 [==============================] - 10s 854us/step - loss: 2.2661 - accuracy: 0.4204\n",
      "Epoch 7/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 2.2541 - accuracy: 0.4267\n",
      "Epoch 8/300\n",
      "11345/11345 [==============================] - 10s 851us/step - loss: 2.2265 - accuracy: 0.4315\n",
      "Epoch 9/300\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 2.2097 - accuracy: 0.4320\n",
      "Epoch 10/300\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 2.1909 - accuracy: 0.4375\n",
      "Epoch 11/300\n",
      "11345/11345 [==============================] - 10s 849us/step - loss: 2.1821 - accuracy: 0.4418\n",
      "Epoch 12/300\n",
      "11345/11345 [==============================] - 10s 851us/step - loss: 2.1656 - accuracy: 0.4421\n",
      "Epoch 13/300\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 2.1490 - accuracy: 0.4447\n",
      "Epoch 14/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 2.1314 - accuracy: 0.4548\n",
      "Epoch 15/300\n",
      "11345/11345 [==============================] - 10s 851us/step - loss: 2.1192 - accuracy: 0.4533\n",
      "Epoch 16/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 2.1090 - accuracy: 0.4566\n",
      "Epoch 17/300\n",
      "11345/11345 [==============================] - 10s 855us/step - loss: 2.1049 - accuracy: 0.4537\n",
      "Epoch 18/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 2.0849 - accuracy: 0.4571\n",
      "Epoch 19/300\n",
      "11345/11345 [==============================] - 10s 853us/step - loss: 2.0581 - accuracy: 0.4653\n",
      "Epoch 20/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 2.0532 - accuracy: 0.4677\n",
      "Epoch 21/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 2.0270 - accuracy: 0.4738\n",
      "Epoch 22/300\n",
      "11345/11345 [==============================] - 10s 872us/step - loss: 2.0119 - accuracy: 0.4773\n",
      "Epoch 23/300\n",
      "11345/11345 [==============================] - 10s 854us/step - loss: 1.9965 - accuracy: 0.4799\n",
      "Epoch 24/300\n",
      "11345/11345 [==============================] - 10s 853us/step - loss: 1.9899 - accuracy: 0.4819\n",
      "Epoch 25/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 1.9747 - accuracy: 0.4861\n",
      "Epoch 26/300\n",
      "11345/11345 [==============================] - 10s 859us/step - loss: 1.9617 - accuracy: 0.4896\n",
      "Epoch 27/300\n",
      "11345/11345 [==============================] - 10s 858us/step - loss: 1.9526 - accuracy: 0.4859\n",
      "Epoch 28/300\n",
      "11345/11345 [==============================] - 10s 859us/step - loss: 1.9374 - accuracy: 0.4948\n",
      "Epoch 29/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 1.9319 - accuracy: 0.4955\n",
      "Epoch 30/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 1.9137 - accuracy: 0.4932\n",
      "Epoch 31/300\n",
      "11345/11345 [==============================] - 10s 855us/step - loss: 1.9012 - accuracy: 0.5012\n",
      "Epoch 32/300\n",
      "11345/11345 [==============================] - 10s 861us/step - loss: 1.8864 - accuracy: 0.5072\n",
      "Epoch 33/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 1.8590 - accuracy: 0.5137\n",
      "Epoch 34/300\n",
      "11345/11345 [==============================] - 10s 858us/step - loss: 1.8517 - accuracy: 0.5141\n",
      "Epoch 35/300\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 1.8399 - accuracy: 0.5170\n",
      "Epoch 36/300\n",
      "11345/11345 [==============================] - 10s 858us/step - loss: 1.8312 - accuracy: 0.5185\n",
      "Epoch 37/300\n",
      "11345/11345 [==============================] - 10s 858us/step - loss: 1.8254 - accuracy: 0.5208\n",
      "Epoch 38/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 1.8067 - accuracy: 0.5216\n",
      "Epoch 39/300\n",
      "11345/11345 [==============================] - 10s 851us/step - loss: 1.7942 - accuracy: 0.5229\n",
      "Epoch 40/300\n",
      "11345/11345 [==============================] - 10s 855us/step - loss: 1.7782 - accuracy: 0.5310\n",
      "Epoch 41/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 1.7662 - accuracy: 0.5314\n",
      "Epoch 42/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 1.7486 - accuracy: 0.5373\n",
      "Epoch 43/300\n",
      "11345/11345 [==============================] - 10s 861us/step - loss: 1.7365 - accuracy: 0.5437\n",
      "Epoch 44/300\n",
      "11345/11345 [==============================] - 10s 891us/step - loss: 1.7251 - accuracy: 0.5431\n",
      "Epoch 45/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.7243 - accuracy: 0.5423\n",
      "Epoch 46/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.7098 - accuracy: 0.5461\n",
      "Epoch 47/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.7125 - accuracy: 0.5438\n",
      "Epoch 48/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 1.6833 - accuracy: 0.5514\n",
      "Epoch 49/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 1.6818 - accuracy: 0.5535\n",
      "Epoch 50/300\n",
      "11345/11345 [==============================] - 10s 864us/step - loss: 1.6601 - accuracy: 0.5610\n",
      "Epoch 51/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 1.6459 - accuracy: 0.5629\n",
      "Epoch 52/300\n",
      "11345/11345 [==============================] - 10s 874us/step - loss: 1.6348 - accuracy: 0.5657\n",
      "Epoch 53/300\n",
      "11345/11345 [==============================] - 10s 870us/step - loss: 1.6338 - accuracy: 0.5668\n",
      "Epoch 54/300\n",
      "11345/11345 [==============================] - 10s 868us/step - loss: 1.6191 - accuracy: 0.5662\n",
      "Epoch 55/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.6026 - accuracy: 0.5763\n",
      "Epoch 56/300\n",
      "11345/11345 [==============================] - 10s 869us/step - loss: 1.5975 - accuracy: 0.5762\n",
      "Epoch 57/300\n",
      "11345/11345 [==============================] - 10s 876us/step - loss: 1.5916 - accuracy: 0.5742\n",
      "Epoch 58/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.5804 - accuracy: 0.5802\n",
      "Epoch 59/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.5543 - accuracy: 0.5858\n",
      "Epoch 60/300\n",
      "11345/11345 [==============================] - 10s 864us/step - loss: 1.5464 - accuracy: 0.5878\n",
      "Epoch 61/300\n",
      "11345/11345 [==============================] - 10s 866us/step - loss: 1.5511 - accuracy: 0.5892\n",
      "Epoch 62/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 1.5393 - accuracy: 0.5892\n",
      "Epoch 63/300\n",
      "11345/11345 [==============================] - 10s 885us/step - loss: 1.5251 - accuracy: 0.5923\n",
      "Epoch 64/300\n",
      "11345/11345 [==============================] - 10s 864us/step - loss: 1.5004 - accuracy: 0.5996\n",
      "Epoch 65/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 1.4919 - accuracy: 0.6038\n",
      "Epoch 66/300\n",
      "11345/11345 [==============================] - 10s 893us/step - loss: 1.4802 - accuracy: 0.6039\n",
      "Epoch 67/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 1.4733 - accuracy: 0.6069\n",
      "Epoch 68/300\n",
      "11345/11345 [==============================] - 10s 858us/step - loss: 1.4653 - accuracy: 0.6055\n",
      "Epoch 69/300\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 1.4474 - accuracy: 0.6154\n",
      "Epoch 70/300\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 1.4435 - accuracy: 0.6132\n",
      "Epoch 71/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 1.4434 - accuracy: 0.6096\n",
      "Epoch 72/300\n",
      "11345/11345 [==============================] - 10s 858us/step - loss: 1.4314 - accuracy: 0.6140\n",
      "Epoch 73/300\n",
      "11345/11345 [==============================] - 10s 856us/step - loss: 1.4129 - accuracy: 0.6215\n",
      "Epoch 74/300\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 1.4117 - accuracy: 0.6212\n",
      "Epoch 75/300\n",
      "11345/11345 [==============================] - 10s 857us/step - loss: 1.3990 - accuracy: 0.6251\n",
      "Epoch 76/300\n",
      "11345/11345 [==============================] - 9s 828us/step - loss: 1.3848 - accuracy: 0.6287\n",
      "Epoch 77/300\n",
      "11345/11345 [==============================] - 9s 830us/step - loss: 1.3717 - accuracy: 0.6325\n",
      "Epoch 78/300\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 1.3711 - accuracy: 0.6348\n",
      "Epoch 79/300\n",
      "11345/11345 [==============================] - 9s 832us/step - loss: 1.3543 - accuracy: 0.6381\n",
      "Epoch 80/300\n",
      "11345/11345 [==============================] - 9s 834us/step - loss: 1.3508 - accuracy: 0.6383\n",
      "Epoch 81/300\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 1.3457 - accuracy: 0.6361\n",
      "Epoch 82/300\n",
      "11345/11345 [==============================] - 9s 819us/step - loss: 1.3148 - accuracy: 0.6469\n",
      "Epoch 83/300\n",
      "11345/11345 [==============================] - 10s 914us/step - loss: 1.3028 - accuracy: 0.6530\n",
      "Epoch 84/300\n",
      "11345/11345 [==============================] - 11s 991us/step - loss: 1.3002 - accuracy: 0.6550\n",
      "Epoch 85/300\n",
      "11345/11345 [==============================] - 10s 901us/step - loss: 1.2852 - accuracy: 0.6548\n",
      "Epoch 86/300\n",
      "11345/11345 [==============================] - 10s 854us/step - loss: 1.2852 - accuracy: 0.6527\n",
      "Epoch 87/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 1.2755 - accuracy: 0.6561\n",
      "Epoch 88/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 1.2553 - accuracy: 0.6597\n",
      "Epoch 89/300\n",
      "11345/11345 [==============================] - 9s 830us/step - loss: 1.2461 - accuracy: 0.6661\n",
      "Epoch 90/300\n",
      "11345/11345 [==============================] - 9s 800us/step - loss: 1.2366 - accuracy: 0.6689\n",
      "Epoch 91/300\n",
      "11345/11345 [==============================] - 9s 781us/step - loss: 1.2232 - accuracy: 0.6760\n",
      "Epoch 92/300\n",
      "11345/11345 [==============================] - 9s 782us/step - loss: 1.2172 - accuracy: 0.6745\n",
      "Epoch 93/300\n",
      "11345/11345 [==============================] - 9s 799us/step - loss: 1.2188 - accuracy: 0.6712\n",
      "Epoch 94/300\n",
      "11345/11345 [==============================] - 9s 784us/step - loss: 1.2117 - accuracy: 0.6730\n",
      "Epoch 95/300\n",
      "11345/11345 [==============================] - 9s 783us/step - loss: 1.2041 - accuracy: 0.6762\n",
      "Epoch 96/300\n",
      "11345/11345 [==============================] - 9s 782us/step - loss: 1.1918 - accuracy: 0.6819\n",
      "Epoch 97/300\n",
      "11345/11345 [==============================] - 9s 785us/step - loss: 1.1814 - accuracy: 0.6854\n",
      "Epoch 98/300\n",
      "11345/11345 [==============================] - 9s 783us/step - loss: 1.1737 - accuracy: 0.6861\n",
      "Epoch 99/300\n",
      "11345/11345 [==============================] - 9s 787us/step - loss: 1.1583 - accuracy: 0.6918\n",
      "Epoch 100/300\n",
      "11345/11345 [==============================] - 9s 803us/step - loss: 1.1434 - accuracy: 0.6907\n",
      "Epoch 101/300\n",
      "11345/11345 [==============================] - 9s 804us/step - loss: 1.1291 - accuracy: 0.6985\n",
      "Epoch 102/300\n",
      "11345/11345 [==============================] - 10s 898us/step - loss: 1.1444 - accuracy: 0.6878\n",
      "Epoch 103/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 1.1232 - accuracy: 0.6983\n",
      "Epoch 104/300\n",
      "11345/11345 [==============================] - 9s 837us/step - loss: 1.1163 - accuracy: 0.7020\n",
      "Epoch 105/300\n",
      "11345/11345 [==============================] - 9s 832us/step - loss: 1.1034 - accuracy: 0.7058\n",
      "Epoch 106/300\n",
      "11345/11345 [==============================] - 9s 836us/step - loss: 1.0979 - accuracy: 0.7042\n",
      "Epoch 107/300\n",
      "11345/11345 [==============================] - 9s 834us/step - loss: 1.0931 - accuracy: 0.7056\n",
      "Epoch 108/300\n",
      "11345/11345 [==============================] - 9s 836us/step - loss: 1.0909 - accuracy: 0.7074\n",
      "Epoch 109/300\n",
      "11345/11345 [==============================] - 9s 833us/step - loss: 1.0884 - accuracy: 0.7074\n",
      "Epoch 110/300\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 1.0771 - accuracy: 0.7106\n",
      "Epoch 111/300\n",
      "11345/11345 [==============================] - 9s 833us/step - loss: 1.0601 - accuracy: 0.7151\n",
      "Epoch 112/300\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 1.0375 - accuracy: 0.7227\n",
      "Epoch 113/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 1.0218 - accuracy: 0.7273\n",
      "Epoch 114/300\n",
      "11345/11345 [==============================] - 10s 839us/step - loss: 1.0099 - accuracy: 0.7342\n",
      "Epoch 115/300\n",
      "11345/11345 [==============================] - 10s 854us/step - loss: 1.0008 - accuracy: 0.7377\n",
      "Epoch 116/300\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 0.9966 - accuracy: 0.7345\n",
      "Epoch 117/300\n",
      "11345/11345 [==============================] - 10s 850us/step - loss: 1.0052 - accuracy: 0.7350\n",
      "Epoch 118/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 0.9875 - accuracy: 0.7370\n",
      "Epoch 119/300\n",
      "11345/11345 [==============================] - 10s 852us/step - loss: 0.9815 - accuracy: 0.7371\n",
      "Epoch 120/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 0.9853 - accuracy: 0.7348\n",
      "Epoch 121/300\n",
      "11345/11345 [==============================] - 10s 868us/step - loss: 0.9692 - accuracy: 0.7406\n",
      "Epoch 122/300\n",
      "11345/11345 [==============================] - 10s 859us/step - loss: 0.9577 - accuracy: 0.7468\n",
      "Epoch 123/300\n",
      "11345/11345 [==============================] - 10s 906us/step - loss: 0.9470 - accuracy: 0.7488\n",
      "Epoch 124/300\n",
      "11345/11345 [==============================] - 10s 861us/step - loss: 0.9360 - accuracy: 0.7507\n",
      "Epoch 125/300\n",
      "11345/11345 [==============================] - 10s 883us/step - loss: 0.9248 - accuracy: 0.7542\n",
      "Epoch 126/300\n",
      "11345/11345 [==============================] - 10s 859us/step - loss: 0.9129 - accuracy: 0.7594\n",
      "Epoch 127/300\n",
      "11345/11345 [==============================] - 10s 859us/step - loss: 0.9040 - accuracy: 0.7624\n",
      "Epoch 128/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 0.8983 - accuracy: 0.7614\n",
      "Epoch 129/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.9000 - accuracy: 0.7621\n",
      "Epoch 130/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 0.8968 - accuracy: 0.7610\n",
      "Epoch 131/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 0.8965 - accuracy: 0.7604\n",
      "Epoch 132/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.8725 - accuracy: 0.7736\n",
      "Epoch 133/300\n",
      "11345/11345 [==============================] - 10s 861us/step - loss: 0.8569 - accuracy: 0.7746\n",
      "Epoch 134/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.8584 - accuracy: 0.7766\n",
      "Epoch 135/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.8459 - accuracy: 0.7792\n",
      "Epoch 136/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 0.8515 - accuracy: 0.7759\n",
      "Epoch 137/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.8352 - accuracy: 0.7827\n",
      "Epoch 138/300\n",
      "11345/11345 [==============================] - 10s 861us/step - loss: 0.8206 - accuracy: 0.7863\n",
      "Epoch 139/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 0.8091 - accuracy: 0.7885\n",
      "Epoch 140/300\n",
      "11345/11345 [==============================] - 10s 868us/step - loss: 0.7967 - accuracy: 0.7929\n",
      "Epoch 141/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 0.7881 - accuracy: 0.7952\n",
      "Epoch 142/300\n",
      "11345/11345 [==============================] - 10s 861us/step - loss: 0.7867 - accuracy: 0.7946\n",
      "Epoch 143/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 0.7888 - accuracy: 0.7928\n",
      "Epoch 144/300\n",
      "11345/11345 [==============================] - 10s 863us/step - loss: 0.8090 - accuracy: 0.7878\n",
      "Epoch 145/300\n",
      "11345/11345 [==============================] - 10s 868us/step - loss: 0.7872 - accuracy: 0.7895\n",
      "Epoch 146/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.7782 - accuracy: 0.7950\n",
      "Epoch 147/300\n",
      "11345/11345 [==============================] - 10s 864us/step - loss: 0.7626 - accuracy: 0.8001\n",
      "Epoch 148/300\n",
      "11345/11345 [==============================] - 10s 862us/step - loss: 0.7418 - accuracy: 0.8056\n",
      "Epoch 149/300\n",
      "11345/11345 [==============================] - 10s 866us/step - loss: 0.7243 - accuracy: 0.8144\n",
      "Epoch 150/300\n",
      "11345/11345 [==============================] - 10s 865us/step - loss: 0.7243 - accuracy: 0.8111\n",
      "Epoch 151/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11345/11345 [==============================] - 9s 834us/step - loss: 0.7287 - accuracy: 0.8123\n",
      "Epoch 152/300\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 0.7171 - accuracy: 0.8142\n",
      "Epoch 153/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.7076 - accuracy: 0.8140\n",
      "Epoch 154/300\n",
      "11345/11345 [==============================] - 9s 837us/step - loss: 0.7069 - accuracy: 0.8180\n",
      "Epoch 155/300\n",
      "11345/11345 [==============================] - 9s 837us/step - loss: 0.7019 - accuracy: 0.8184\n",
      "Epoch 156/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 0.7002 - accuracy: 0.8183\n",
      "Epoch 157/300\n",
      "11345/11345 [==============================] - 9s 835us/step - loss: 0.6707 - accuracy: 0.8308\n",
      "Epoch 158/300\n",
      "11345/11345 [==============================] - 10s 848us/step - loss: 0.6542 - accuracy: 0.8353\n",
      "Epoch 159/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.6443 - accuracy: 0.8401\n",
      "Epoch 160/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 0.6527 - accuracy: 0.8346\n",
      "Epoch 161/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.6444 - accuracy: 0.8376\n",
      "Epoch 162/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 0.6431 - accuracy: 0.8374\n",
      "Epoch 163/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 0.6419 - accuracy: 0.8403\n",
      "Epoch 164/300\n",
      "11345/11345 [==============================] - 9s 837us/step - loss: 0.6338 - accuracy: 0.8419\n",
      "Epoch 165/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.6166 - accuracy: 0.8424\n",
      "Epoch 166/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.6131 - accuracy: 0.8449\n",
      "Epoch 167/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 0.6093 - accuracy: 0.8453\n",
      "Epoch 168/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.6037 - accuracy: 0.8459\n",
      "Epoch 169/300\n",
      "11345/11345 [==============================] - 10s 849us/step - loss: 0.5913 - accuracy: 0.8551\n",
      "Epoch 170/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.5856 - accuracy: 0.8539\n",
      "Epoch 171/300\n",
      "11345/11345 [==============================] - 10s 838us/step - loss: 0.5807 - accuracy: 0.8554\n",
      "Epoch 172/300\n",
      "11345/11345 [==============================] - 10s 864us/step - loss: 0.5713 - accuracy: 0.8558\n",
      "Epoch 173/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.5659 - accuracy: 0.8599\n",
      "Epoch 174/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.5474 - accuracy: 0.8657\n",
      "Epoch 175/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.5463 - accuracy: 0.8684\n",
      "Epoch 176/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.5369 - accuracy: 0.8688\n",
      "Epoch 177/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.5220 - accuracy: 0.8755\n",
      "Epoch 178/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.5157 - accuracy: 0.8755\n",
      "Epoch 179/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.5122 - accuracy: 0.8747\n",
      "Epoch 180/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.5275 - accuracy: 0.8729\n",
      "Epoch 181/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.5150 - accuracy: 0.8765\n",
      "Epoch 182/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.5374 - accuracy: 0.8651\n",
      "Epoch 183/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.5370 - accuracy: 0.8652\n",
      "Epoch 184/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.5348 - accuracy: 0.8621\n",
      "Epoch 185/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.4996 - accuracy: 0.8757\n",
      "Epoch 186/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.4835 - accuracy: 0.8850\n",
      "Epoch 187/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.4730 - accuracy: 0.8894\n",
      "Epoch 188/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.4599 - accuracy: 0.8934\n",
      "Epoch 189/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.4485 - accuracy: 0.8963\n",
      "Epoch 190/300\n",
      "11345/11345 [==============================] - 10s 847us/step - loss: 0.4352 - accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.4394 - accuracy: 0.8970\n",
      "Epoch 192/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.4562 - accuracy: 0.8914\n",
      "Epoch 193/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.4393 - accuracy: 0.9002\n",
      "Epoch 194/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.4298 - accuracy: 0.8990\n",
      "Epoch 195/300\n",
      "11345/11345 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.90 - 10s 845us/step - loss: 0.4118 - accuracy: 0.9067\n",
      "Epoch 196/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.3905 - accuracy: 0.9171\n",
      "Epoch 197/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.3880 - accuracy: 0.9145\n",
      "Epoch 198/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.3956 - accuracy: 0.9113\n",
      "Epoch 199/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3913 - accuracy: 0.9160\n",
      "Epoch 200/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.3888 - accuracy: 0.9123\n",
      "Epoch 201/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.4234 - accuracy: 0.8963\n",
      "Epoch 202/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.4465 - accuracy: 0.8862\n",
      "Epoch 203/300\n",
      "11345/11345 [==============================] - 10s 846us/step - loss: 0.4350 - accuracy: 0.8976\n",
      "Epoch 204/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.4084 - accuracy: 0.9049\n",
      "Epoch 205/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.3822 - accuracy: 0.9128\n",
      "Epoch 206/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.3691 - accuracy: 0.9193\n",
      "Epoch 207/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.3499 - accuracy: 0.9258\n",
      "Epoch 208/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3425 - accuracy: 0.9272\n",
      "Epoch 209/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3259 - accuracy: 0.9345\n",
      "Epoch 210/300\n",
      "11345/11345 [==============================] - 10s 846us/step - loss: 0.3083 - accuracy: 0.9402\n",
      "Epoch 211/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3017 - accuracy: 0.9436\n",
      "Epoch 212/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.2970 - accuracy: 0.9436\n",
      "Epoch 213/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.2869 - accuracy: 0.9479\n",
      "Epoch 214/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.2900 - accuracy: 0.9457\n",
      "Epoch 215/300\n",
      "11345/11345 [==============================] - 10s 847us/step - loss: 0.2913 - accuracy: 0.9455\n",
      "Epoch 216/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.3337 - accuracy: 0.9295\n",
      "Epoch 217/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.4011 - accuracy: 0.9013\n",
      "Epoch 218/300\n",
      "11345/11345 [==============================] - 10s 846us/step - loss: 0.4818 - accuracy: 0.8655\n",
      "Epoch 219/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.4456 - accuracy: 0.8837\n",
      "Epoch 220/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3595 - accuracy: 0.9147\n",
      "Epoch 221/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3172 - accuracy: 0.9307\n",
      "Epoch 222/300\n",
      "11345/11345 [==============================] - 10s 847us/step - loss: 0.2711 - accuracy: 0.9499\n",
      "Epoch 223/300\n",
      "11345/11345 [==============================] - 10s 846us/step - loss: 0.2493 - accuracy: 0.9559\n",
      "Epoch 224/300\n",
      "11345/11345 [==============================] - 10s 847us/step - loss: 0.2296 - accuracy: 0.9615\n",
      "Epoch 225/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.2199 - accuracy: 0.9650\n",
      "Epoch 226/300\n",
      "11345/11345 [==============================] - 10s 839us/step - loss: 0.2166 - accuracy: 0.9664\n",
      "Epoch 227/300\n",
      "11345/11345 [==============================] - 10s 914us/step - loss: 0.2106 - accuracy: 0.9692\n",
      "Epoch 228/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.2029 - accuracy: 0.9688\n",
      "Epoch 229/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.2009 - accuracy: 0.9696\n",
      "Epoch 230/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.1990 - accuracy: 0.9699\n",
      "Epoch 231/300\n",
      "11345/11345 [==============================] - 10s 847us/step - loss: 0.1979 - accuracy: 0.9721\n",
      "Epoch 232/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.2129 - accuracy: 0.9661\n",
      "Epoch 233/300\n",
      "11345/11345 [==============================] - 10s 839us/step - loss: 0.2603 - accuracy: 0.9505\n",
      "Epoch 234/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.3614 - accuracy: 0.9074\n",
      "Epoch 235/300\n",
      "11345/11345 [==============================] - 10s 841us/step - loss: 0.4481 - accuracy: 0.8765\n",
      "Epoch 236/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.4011 - accuracy: 0.8947\n",
      "Epoch 237/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.3155 - accuracy: 0.9275\n",
      "Epoch 238/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.2603 - accuracy: 0.9459\n",
      "Epoch 239/300\n",
      "11345/11345 [==============================] - 10s 860us/step - loss: 0.2053 - accuracy: 0.9660\n",
      "Epoch 240/300\n",
      "11345/11345 [==============================] - 10s 847us/step - loss: 0.1710 - accuracy: 0.9758\n",
      "Epoch 241/300\n",
      "11345/11345 [==============================] - 10s 883us/step - loss: 0.1572 - accuracy: 0.9810\n",
      "Epoch 242/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.1484 - accuracy: 0.9839\n",
      "Epoch 243/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.1445 - accuracy: 0.9840\n",
      "Epoch 244/300\n",
      "11345/11345 [==============================] - 10s 842us/step - loss: 0.1418 - accuracy: 0.9857\n",
      "Epoch 245/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.1384 - accuracy: 0.9845\n",
      "Epoch 246/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.1363 - accuracy: 0.9873\n",
      "Epoch 247/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.1329 - accuracy: 0.9869\n",
      "Epoch 248/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.1349 - accuracy: 0.9864\n",
      "Epoch 249/300\n",
      "11345/11345 [==============================] - 10s 844us/step - loss: 0.1424 - accuracy: 0.9855\n",
      "Epoch 250/300\n",
      "11345/11345 [==============================] - 10s 845us/step - loss: 0.1567 - accuracy: 0.9794\n",
      "Epoch 251/300\n",
      "11345/11345 [==============================] - 10s 843us/step - loss: 0.2018 - accuracy: 0.9629\n",
      "Epoch 252/300\n",
      "11345/11345 [==============================] - 63s 6ms/step - loss: 0.3201 - accuracy: 0.9183\n",
      "Epoch 253/300\n",
      "11345/11345 [==============================] - 15s 1ms/step - loss: 0.4181 - accuracy: 0.8861\n",
      "Epoch 254/300\n",
      "11345/11345 [==============================] - 10s 873us/step - loss: 0.3897 - accuracy: 0.8919\n",
      "Epoch 255/300\n",
      "11345/11345 [==============================] - 10s 870us/step - loss: 0.3152 - accuracy: 0.9220\n",
      "Epoch 256/300\n",
      "11345/11345 [==============================] - 10s 875us/step - loss: 0.2305 - accuracy: 0.9532\n",
      "Epoch 257/300\n",
      "11345/11345 [==============================] - 10s 893us/step - loss: 0.1617 - accuracy: 0.9773\n",
      "Epoch 258/300\n",
      "11345/11345 [==============================] - 10s 881us/step - loss: 0.1213 - accuracy: 0.9870\n",
      "Epoch 259/300\n",
      "11345/11345 [==============================] - 10s 868us/step - loss: 0.1087 - accuracy: 0.9918\n",
      "Epoch 260/300\n",
      "11345/11345 [==============================] - 11s 951us/step - loss: 0.1018 - accuracy: 0.9916\n",
      "Epoch 261/300\n",
      "11345/11345 [==============================] - 10s 879us/step - loss: 0.0973 - accuracy: 0.9927\n",
      "Epoch 262/300\n",
      "11345/11345 [==============================] - 11s 946us/step - loss: 0.0932 - accuracy: 0.9941\n",
      "Epoch 263/300\n",
      "11345/11345 [==============================] - 10s 910us/step - loss: 0.0911 - accuracy: 0.9937\n",
      "Epoch 264/300\n",
      "11345/11345 [==============================] - 11s 938us/step - loss: 0.0883 - accuracy: 0.9943\n",
      "Epoch 265/300\n",
      "11345/11345 [==============================] - 9s 831us/step - loss: 0.0858 - accuracy: 0.9943\n",
      "Epoch 266/300\n",
      "11345/11345 [==============================] - 12s 1ms/step - loss: 0.0845 - accuracy: 0.9947\n",
      "Epoch 267/300\n",
      "11345/11345 [==============================] - 10s 871us/step - loss: 0.0851 - accuracy: 0.9938\n",
      "Epoch 268/300\n",
      "11345/11345 [==============================] - 9s 793us/step - loss: 0.0830 - accuracy: 0.9958\n",
      "Epoch 269/300\n",
      "11345/11345 [==============================] - 9s 798us/step - loss: 0.0817 - accuracy: 0.9949\n",
      "Epoch 270/300\n",
      "11345/11345 [==============================] - 9s 826us/step - loss: 0.0855 - accuracy: 0.9933\n",
      "Epoch 271/300\n",
      "11345/11345 [==============================] - 9s 795us/step - loss: 0.0977 - accuracy: 0.9928\n",
      "Epoch 272/300\n",
      "11345/11345 [==============================] - 9s 803us/step - loss: 0.1279 - accuracy: 0.9822\n",
      "Epoch 273/300\n",
      "11345/11345 [==============================] - 9s 793us/step - loss: 0.2885 - accuracy: 0.9265\n",
      "Epoch 274/300\n",
      "11345/11345 [==============================] - 9s 801us/step - loss: 0.5486 - accuracy: 0.8409\n",
      "Epoch 275/300\n",
      "11345/11345 [==============================] - 9s 801us/step - loss: 0.5123 - accuracy: 0.8493\n",
      "Epoch 276/300\n",
      "11345/11345 [==============================] - 9s 792us/step - loss: 0.3049 - accuracy: 0.9166\n",
      "Epoch 277/300\n",
      "11345/11345 [==============================] - 9s 791us/step - loss: 0.1779 - accuracy: 0.9660\n",
      "Epoch 278/300\n",
      "11345/11345 [==============================] - 9s 791us/step - loss: 0.1113 - accuracy: 0.9866\n",
      "Epoch 279/300\n",
      "11345/11345 [==============================] - 9s 792us/step - loss: 0.0812 - accuracy: 0.9952\n",
      "Epoch 280/300\n",
      "11345/11345 [==============================] - 9s 790us/step - loss: 0.0690 - accuracy: 0.9969\n",
      "Epoch 281/300\n",
      "11345/11345 [==============================] - 9s 793us/step - loss: 0.0643 - accuracy: 0.9971\n",
      "Epoch 282/300\n",
      "11345/11345 [==============================] - 9s 790us/step - loss: 0.0606 - accuracy: 0.9978\n",
      "Epoch 283/300\n",
      "11345/11345 [==============================] - 10s 840us/step - loss: 0.0585 - accuracy: 0.9980\n",
      "Epoch 284/300\n",
      "11345/11345 [==============================] - 10s 848us/step - loss: 0.0561 - accuracy: 0.9979\n",
      "Epoch 285/300\n",
      "11345/11345 [==============================] - 9s 810us/step - loss: 0.0550 - accuracy: 0.9986\n",
      "Epoch 286/300\n",
      "11345/11345 [==============================] - 9s 792us/step - loss: 0.0528 - accuracy: 0.9982\n",
      "Epoch 287/300\n",
      "11345/11345 [==============================] - 9s 829us/step - loss: 0.0515 - accuracy: 0.9989\n",
      "Epoch 288/300\n",
      "11345/11345 [==============================] - 9s 837us/step - loss: 0.0503 - accuracy: 0.9989\n",
      "Epoch 289/300\n",
      "11345/11345 [==============================] - 9s 834us/step - loss: 0.0487 - accuracy: 0.9991\n",
      "Epoch 290/300\n",
      "11345/11345 [==============================] - 10s 885us/step - loss: 0.0478 - accuracy: 0.9989\n",
      "Epoch 291/300\n",
      "11345/11345 [==============================] - 10s 882us/step - loss: 0.0465 - accuracy: 0.9989\n",
      "Epoch 292/300\n",
      "11345/11345 [==============================] - 10s 875us/step - loss: 0.0455 - accuracy: 0.9992\n",
      "Epoch 293/300\n",
      "11345/11345 [==============================] - 10s 877us/step - loss: 0.0472 - accuracy: 0.9985\n",
      "Epoch 294/300\n",
      "11345/11345 [==============================] - 10s 876us/step - loss: 0.0466 - accuracy: 0.9988\n",
      "Epoch 295/300\n",
      "11345/11345 [==============================] - 10s 874us/step - loss: 0.0449 - accuracy: 0.9990\n",
      "Epoch 296/300\n",
      "10240/11345 [==========================>...] - ETA: 0s - loss: 0.0428 - accuracy: 0.9989"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=300,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('epoch400.h5')\n",
    "# save the tokenizer\n",
    "from pickle import dump,load\n",
    "dump(tokenizer, open('my_token', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
